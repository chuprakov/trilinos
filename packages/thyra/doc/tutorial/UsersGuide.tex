\documentclass[12pt]{article}
\newcommand{\home}{/home/ptboggs}
%\input{\home/tex/defs}
\usepackage{verbatim}
\usepackage{alltt}
\usepackage{fancyvrb}
% Use the next two lines to change the enumerate labels.  Modify the
% \enumer command as appropriate
%\input{\home/tex/enum}
%\enumer{\arabic}{\alph}{\roman}{\arabic}


%\thispagestyle{empty}
%\eqnbysection
%\typein[\iof]{Enter includeonly file}
%\includeonly{\iof}
\newcommand{\bd}{\begin{displaymath}}
\newcommand{\ed}{\end{displaymath}}
\newcommand{\trp}{^{\sf T}}
\newcommand{\inv}{^{-1}}
\newcommand{\bry}{\begin{array}}
\newcommand{\ery}{\end{array}}



\newcommand{\thyra}{{\sf Thyra}}
\newcommand{\tri}{{\sf Trilinos}}
\newcommand{\teuchos}{{\sf Teuchos}}
\newcommand{\matlab}{{\sf Matlab}}
\newcommand{\rcp}{{\sf RCP}}
\newcommand{\epetra}{{\sf EPetra}}
\newcommand{\cpp}{{\sf C++}}
\newcommand{\template}{{\sf template}}
\newcommand{\paramList}{{\sf ParameterList}}
\newcommand{\xml}{{\sf XML}}


\renewcommand{\vector}{{\sf Vector}}
\newcommand{\vectorSpace}{{\sf VectorSpace}}
\newcommand{\vectorType}{{\sf VectorType}}
\newcommand{\linearOp}{{\sf LinearOperator}}

\newcommand{\float}{{\tt float}}
\newcommand{\double}{{\tt double}}
\renewcommand{\int}{{\tt int}}
\newcommand{\complex}{{\tt complex}}


\newcommand{\lcode}[1]{{\tt #1}}
\newenvironment{test}{\begin{verbatim}}{}

\newenvironment{dcode}{  \begin{center} 
    \begin{minipage}{.9\textwidth}
     \begin{alltt}}
{\end{alltt}
    \end{minipage}
  \end{center}}

\newcommand{\bdcode}{\begin{dcode}}
\newcommand{\edcode}{\end{dcode}}

%\newcommand{\dcode}[1]{
%  \begin{center} 
%    \begin{minipage}{.9\textwidth}
%      \begin{Verbatim} 
%        #1
%      \end{Verbatim} 
%    \end{minipage}
%  \end{center}}

\sloppy

%\title{Thyra User's Guide}
\title{Thyra \\  A Tutorial}
\author{Paul T. Boggs, Victoria Howle, Kevin R. Long (8962)
   \and Roscoe A. Bartlett (1411)}

\begin{document}
\maketitle


\section{Introduction}

\thyra\ is a set of software tools designed to ease the use of many of
the software packages in \tri.  It can be used to develop further
sophisticated tools or to develop complex applications.  \thyra\
accomplishes this by providing an abstract vector and matrix
interface.

Since there are many such abstract interfaces, what special design
features of \thyra, one may ask,  recommend its adoption over its
competitors?   The answer
is that \thyra\ provides ease of use, a full set of well designed
features, consistency throughout the package,  operator overloading
that allows the construction of code that looks much like standard
mathematical descriptions, i.e., like \matlab,  automatic memory
management, extensive error checking (in debug mode), and very high
efficiency in both serial and parallel applications. This last point,
efficiency, is of paramount importance, since the ultimate target of
\thyra\ is large scale applications.  Furthermore, as an abstract
interface, \thyra\ makes no assumption about the underlying
representation of the vectors and matrices.  Thus applications can
delay this choice until the very end, and change this decision easily,
so that different concrete implementations can be used as
appropriate.  For example, one may want to use a simple serial vector
and an in-core matrix representation for small test problems and a
distributed vector and matrix implementation for large
problems where parallel processing is required. Just as vector and
matrix representations can be easily changed, the linear solvers from
\tri\ packages can also be easily changed, thus providing an
application considerable flexibility in choosing the best
representations and appropriate solvers (and preconditioners).

To illustrate the power of \thyra\ we show an example that is familiar
to many, namely the solution of a symmetric positive definite linear
system by the conjugate gradient (CG) method.  Assume that we wish to solve
the linear system
\bd
   Ax = b
\ed 
where $A$ is a symmetric positive definite $(n \times n)$ matrix and
$x$ and $b$ are 
vectors of length $n$.  Assume that the code to set up $A$ and $b$ has
been written (we'll illustrate this soon). Then the mathematical
description of the conjugate gradient method and \thyra\ code are
shown in the left-hand and right-hand columns, respectively, in the
figure \ref{fig11}.

From figure 1 it is easy to see that \thyra\ allows code to look
almost exactly like the corresponding mathematical description.  Note
that the operators * and + had to be overloaded to make this
possible.  For example, a scalar times a vector is written as {\tt
  alpha * x} which means to multiply every element of the vector {\tt x} by
the scalar {\tt alpha}.  When we write {\tt r * p}, however, we are
``multiplying'' two vectors and this is defined as the inner product,
or $r \trp p$.  These and other choices are discussed in section
\ref{handle} .

Please note, however, that this code is not meant to illustrate
``good'' coding practice for the CG method.  First, given that the CG
method is only appropriate for large problems, the computation of {\tt
A * p}
should be done once, saved, and reused where needed.  Second, as
experts in iterative linear solvers will attest, many safeguards and
options need to be added to any production-quality version of CG. But
note that \thyra\ supports prototype code, as in figure \ref{fig11},
and then more efficient code as one develops confidence in the results.


\begin{figure}[t] \label{fig11}
\begin{center}
{\bf The Conjugate Gradient Algorithm} 
\end{center}
\begin{minipage}[t]{.6\textwidth}Given an initial approximation, $x_0$; \\
      Set $r_0 \leftarrow Ax_0 - b$; \\
      Set $p_0 \leftarrow r_0$; \\
      Set $k \leftarrow 0$; \\
\end{minipage}
      
\begin{tabular}{|l|l|} \hline
Mathematical Description& \thyra\ Code \\ \hline
While $r_k \neq 0$     & {\tt while r.norm2() \verb+>+= tol \{} \\
$\alpha_k \leftarrow -\frac{r_k \trp p_k}{p_k\trp Ap_k}$ & {\tt \ \  alpha = -(r *
p) / (p * (A * p));} \\
$x_{k+1} \leftarrow x_k + \alpha_k p_k$ & {\tt \ \ x = x + alpha * p;} \\
$r_{k+1} \leftarrow Ax_{k+1} - b$    & {\tt \ \ r = A * x - b;} \\
$\beta_{k+1} = \frac{r_{k+1}\trp A p_k}{p_kAp_k}$   & {\tt \ \ beta = (r * (A *
p)) / (p * (A * p));} \\
$p_{k+1} \leftarrow - r_{k+1} + \beta_{k+1} p_k$;  & {\tt \ \ p = -r + beta *
p;} \\
$k \leftarrow k + 1$;   & \} \\ \hline
\end{tabular}
\caption{CG as in a textbook vs. CG in \thyra}
\end{figure}

 
A few final remarks need to be made before getting into the details.
\begin{itemize}
    \item First, there is the natural question, ``For what, if
  anything, is \thyra\ not appropriate.''  Recall that \thyra\ was
  designed to be efficient primarily for large scale problems. We have
  taken much care to minimize the overhead of using \thyra\ and, as one
  can see from the timing results in section \ref{timing}, there is no
  noticeable penalty on large problems.  For very small problems,
  however, this penalty can be significant.  For example, for an
  application in visualization that requires many matrix-vector
  operations on $(3 \times 3)$ matrices, using \thyra, even with dense
  storage of the matrices and vectors would be inefficient.
    \item The overall strategy for thinking about matrices and vectors
  that are used in \thyra\ is in keeping with trends in the field that
  began with the Hilbert-Class Library (HCL) of Achenbach and Symes.
  See section \ref{refs} for some references.
    \item \thyra\ has two levels designed to meet the needs and tastes
  of a diverse group of programmers, from abstract numerical
  algorithms developers to applications implementors.  At the base is
  the abstraction layer which contains a relatively small set of powerful
  abstractions.  The ``handle'' layer provides ease of use features such
  as the overloaded operators mentioned above that make codes look like
  \matlab.  The handle layer also uses some of the utilities in
  \teuchos.  Whether you choose the abstraction layer or the
  handle layer, efficiency is paramount.
    \item This guide was written to be used on-line so that the reader
  can easily go from this guide to the Doxygen documentation for
  \thyra, \teuchos, or any of the other \tri\ packages.  The sections
  are outlined below; they do not have to be read in order and some of
  them can be skimmed first or read later.
    \item As an attempt to ensure that this documentation is up to
  date, all of the code snippets are taken from actual codes that are
  part of the test suite that is run after any change.  Thus these
  codes must compile and run before changes can be accepted.
\end{itemize}


Sections:
\begin{description}
    \item [The handle layer of \thyra] Here we describe the highest
  level of \thyra\ that, we believe, most users will find most
  natural.  We recommend that the new reader start here to get a feel
  for how \thyra\ is used and for the power and clarity of expression
  that it affords.
    \item [The abstraction layer of \thyra] This is the base level that
  supports the handle layer and allows the user to have direct access
  to the underlying abstractions.
    \item [An overview of the design of \thyra] This covers in some
  detail the object-oriented design philosophy and features that
  enable efficiency and easy extensibility to new tools as they become
  available.  Some of the topics are covered in part in the other sections,
  but this section gives a more consistent and detailed description.
  This can be read at the beginning for those who like to get these
  details early, or later after, say, the handle layer is studied.
    \item [Timing studies] As mentioned above, there is virtually no
  penalty for using these powerful tools for modest to large scale
  matrices and vectors.  In this section, we summarize these results.
    \item [References] Also as previously noted, \thyra\ is part of a
  broad movement in scientific computation towards this style of
  design.  Here we give some relevant references to complementary
  efforts of other groups.
\end{description}



%============================================================================
\section{The Handle Layer of \thyra} \label{handle}

\subsection{What is a ``handle''?} \label{handleIntro}

As noted is section \ref{design} on the design of \thyra, we make
extensive use of design patterns (see references in \ref{refs}) in our
implementations. 
A ``handle'' is a design pattern that provides a mechanism for
managing the memory and use of a collection of derived classes.  Thus
a handle has a pointer (usually a reference-counted pointer (to be
discussed momentarily)) to the particular derived class and a
collection of methods that reflect most, if not all, of the methods of
the derived classes.  A reference-counted pointer is another design
pattern that keeps a pointer to an object along with a counter of the
number of times that particular object is referenced by any other
object.  On construction of the object, call it object A, memory can
be allocated and the counter is set to 1.  Any time another object
points to object A, the counter is incremented.  Any time that other
object no longer points to object A, the counter is decremented and,
if the counter reaches zero, the memory can be safely deallocated. By
using a handle with an underlying reference-counted pointer, memory
for matrices and vectors in \thyra\ can be automatically managed, thus
freeing the user from one of the most difficult and error-prone
aspects of debugging a complex numerical code.

As noted, a handle contains methods for most of the methods appearing
in the main class and the derived classes.  If a method only appears
in some of the derived classes, the handle must cast the pointer to an
appropriate pointer for the derived class and then call the method.
To do this, of course, the handle must know about the methods in the
derived classes, but this is not always the case.  In cases where the
functions are not known to the handle, the
user must do the cast before calling the method.  An important design
feature of \thyra\ is that as many errors as possible should be caught
at compile time and that, when there are run-time errors, consistent
and understandable error 
messages be issued; the use of handles 
facilitates this. 

In the handle layer of \thyra, we use a variety of handles, the most
common of which are  \vector,
\vectorSpace, and \linearOp.  Almost all of the commonly used functions
for these objects are included at the handle level, but some of the
more specialized methods are not.  For example, since \thyra\ is
designed for large-scale problems and matrix factorizations are
usually impossible for many sparse implementations, the methods to do
these factorizations are primarily confined to dense storage
implementations and the user must do the cast to obtain access to
these methods.  We'll show examples of this later.

Inevitably, the issue of performance arises.
The use of handles and reference-counted pointers incurs a very modest
cost that is unnoticeable on large problems.  See section \ref{timing} for
timing runs that show this.

The handle layer also has methods that describe what object each
handle contains.  These methods, \lcode{description} and
\lcode{describe} will be discussed below in context.

Finally, we note that the reference-counted pointer that we use can
and is used in a number of other applications.  It is implemented in
the \teuchos\ package of \tri\ as \rcp.



%   - A handle is a design pattern (ref) that provides a capability to
%   take care of a number of related classes 
%   - it takes a special pointer, called a reference-counted pointer,
%   to the particular object and the set of almost all operations that
%   can be called on any of the objects that are handles.  There may be
%   a few, very special, operations that are only available on special
%   types, and these must be dealt with separately by the user.  We'll
%   show some examples of this below. 
%   - A ref-counted pointer is a memory management device that keeps
%   track of the number of active references to each object.  Only when
%   that number goes to zero can the object be safely deleted. 
%   - Thus the use of handles frees the user from many of the most
%   difficult and error-prone aspects of allocating and freeing memory.
%   - Using handles frees the user from these issues and lets him/her
%   concentrate on the real problem or application.
%   - In example of linear ops, there is a LinearOperator handle that
%   takes care 
%   of all linear ops.
%   - Linear ops have lots of different properties.  For example, some
%   are loadable, but some, like the specially designed
%   IdentityOperator is not.  If you try to load the IdentityOp, the
%   handle will catch 
%   this error and give you a useful error message.
%   - There is a handle for Vector, VectorSpace (described next)
%   LinearOperator
%   - The Vector handle, therefore, wraps an underlying vector object
%   in a ref-counted pointer and contains all of the methods.
%   - Yes, there is a very small performance penalty for using this,
%   but it is completely swamped by the real ops in any sizeable
%   application.  


\subsection{A First Look at \vectorSpace s and \vector s} \label{introVec}

In most programming languages there is a two-step process to set up
and use the memory space for a vector.  \thyra\ also requires a
two-step process, but does so in a more modern way.  Since \thyra\ 
does not require any information about the underlying implementation
of a vector and, because there may be several different vector types
used in the same application, \thyra\ aims to specify and use the
information in an implementation-independent way as much as possible.
At some point, however, the user must choose a particular vector type,
e.g., \epetra, and that type will have some implementation-dependent
information that will be required.  But, this information can be
supplied at run-time, and the underlying application can be coded
without this knowledge.  The advantage is that different vector types
and different matrix storage schemes can be tried with no change to
the basic implementation --- all of the necessary changes can be made
at the highest level at the last minute and may even be based on an
input file.


\thyra\ uses the mathematical convention that vectors are elements of
a vector space.  The properties of the vector space thereby determine the
properties of the vectors in that space.  Thus in \thyra, one first
defines a vector space and then uses that space to create concrete
members as required.   That is, you do NOT create the vectors
directly, but rather you create the vector space and use the
\lcode{createMember} function of that space to create vectors.  
As noted above, both \vector\ and \vectorSpace\ are handles, and so 
in
addition to the advantages outlined above for handles, this design
also allows detailed and efficient error checking to take place to ensure that
vectors are compatible before, say, adding them together. 

In \thyra\ there are several ``concrete'' implementations of vector
spaces and vectors, including \epetra, and  other implementations can
be easily added.

A major design criterion of \thyra\ is that as much code as possible
be reusable. In particular, we wanted the code that adds two vectors
to work whether the vectors contain \float s, \double s, \int s, or
\complex\ elements.  This design drastically reduces the number of
methods and implementations that must be written and maintained.
\cpp\ facilitates such a design by the use of \template s; \thyra\ is
completely \template d.

A first example: \\
We'll use \epetra\ as the underlying vector type.  First, we'll
create an \epetra\ vector space, but, for now, we'll skip the details
of the constructor.  Let's assume we want a vector of \double s.
\bdcode
VectorSpace<double> space = new EpetraVectorSpace(...); 
Vector<double> vec = space.createMember(); 
\edcode
The first line sets up a variable called \lcode{space} which is an
\epetra\ \vectorSpace.  Again, we have skipped the arguments of the
constructor, but we'll cover that soon.  Notice that the \cpp\ way to
indicate that this is a vector of \double 's is to use the template
notation of \lcode{<double>}.  The second line allocates the space for
the vector as necessary.  For example, \epetra\ is designed for use on
parallel processors where the elements of a vector are spread over the
processors.  The \lcode{createMember} function calls the underlying
implementation of \epetra, which allocates the vector.  Again, note that
if we change the first line to create a different type of vector
space, the second line remains the same.


The next task is to load the vector with useful data. As a first
example, we'll simply set all of the elements to a constant value
using one of the global functions on \vector.  
\bdcode
setToConstant(vec, 2.0);
\edcode
We'll discuss other ways to set the values of the elements of a vector
shortly.

% Here, we'll
%just fill it with its index value, but, clearly, you could fill it
%with any data. Assume that the vector \lcode{vec} has length
%\lcode{n}. 
%\dcode{for int i = 0; i < n; i++) \\
%\{ \\
%   vec[i] = double(i); \\
%\}
%}

%This shows that we can access any element of a vector by putting its index
%in square brackets.  This works on either side of the equal sign.
If we create a second vector, e.g., by using
\bdcode
Vector<double> vec2 = space.createMember();
\edcode 
and fill it, e.g., 
%\dcode{for int i = 0; i < n; i++) \\
%\{ \\
%   vec2[i] = double(i + 10); \\
%\}
%}
\bdcode
setToConstant(vec2, 3.0);
\edcode
 then we can perform operations on these, e.g.,
\bdcode
Vector<double> vectorSum = vec + vec2;
\edcode
A couple of points need to be made.  
\begin{itemize}
    \item We could create as many
vectors as necessary with the \lcode{createMember} function.  
  \item The variable \lcode{vectorSum} is automatically defined by virtue of
being assigned a vector value.  That is, the memory allocation and
vector type assignment is automatically performed.  
  \item The
operator \lcode{+} has been overloaded to allow a convenient and
easily readable notation. There is a similarly overloaded operator for
subtraction (-); the overloaded operator \lcode{*} implies the ``dot
product'' or ``inner product'' and results in a scalar value --- note
that it is the same scalar value as the vector is \template d on, in
this case \double.  The operator \lcode{/} is not defined, since
vector division is not mathematically defined.  
    \item This is, in principle,  equivalent to the code
        \bdcode
Vector<double> vectorSum = vec.space().createMember();
int n = vec.space().dim(); 
for (int i = 0; i < n; i++) 
  \{ 
    vectorSum[i] = vec[i] + vec2[i]; 
  \}
\edcode
where the function \lcode{dim()} gives the dimension of the vector
space (the length of the vector) and the use of the square brackets
allows access to the individual elements (assuming such access is
allowed). 
The former, however, is much clearer in its intent, much easier to read, and
much easier to debug. Note that in the former code it doesn't matter how
long the vector is, we just write \lcode{vectorSum = vec + vec2;} and we are
done.  Furthermore, and this is important, the one line implementation
will be much faster in general, since there may be a very efficient
implementation under the hood. 
%And, even more importantly, the loop
%version may not run correctly in parallel.  As many who have tried to
%implement so-called single process, multiple data (SPMD) codes
%already know, setting off-processor values can often 
%cause problems, so in parallel, one first has to get the range of
%indices on the local processor and limit the loop by these.  The code
%for this is the following:
%\dcode{int low = vec.lowestLocallyOwnedIndex(); \\
%       int numElements  = vec.numLocalElements(); \\
%       for (int i = low; i < low + numElements; i++) \\
%       \{\\
%          vectorSum[i] = vec[i] + vec2[i]; \\
%         \} }
More on this topic is in subsection \ref{moreVec} where we address
this issue in the context of parallel processing.
%For example, the loop method with
%individual memory access would not be executed in parallel even if the
%underlying vectors were distributed across the processors.  The
%one-line version would call the underlying ``add operation'' on the
%vector, which is presumably very efficient, as it is in \epetra.
  \item This operation raises an often confusing issue for users of
\cpp.  How does
\bdcode
Vector<double> vectorSum = vec; 
vectorSum = vectorSum + vec2;
\edcode
differ from \lcode{Vector<double> vectorSum = vec + vec2;}?  The
question boils down to what happens in the statement
\bdcode
Vector<double> vectorSum = vec;
\edcode
This statement uses the \cpp\ convention that the new vector
\lcode{vectorSum} {\em points} to the vector \lcode{vec}, i.e.,
they are different names for the same object.  Thus, having done this,
when the second line, 
\bdcode
vectorSum = vectorSum + vec2;
\edcode 
is executed, the
result will be in \lcode{vectorSum}, BUT, since \lcode{vec} points to
the same place, it will also contain the sum and the original value of
\lcode{vec} is lost.  The way to force a real copy of \lcode{vec} is
to do the following:
\bdcode
Vector<double> vectorSum = vec.copy(); 
vectorSum = vectorSum + vec2;
\edcode
We'll explain why this is consistent in subsection \ref{moreVec}.
  \item Component-wise multiplication (division) of vectors, i.e.,
where the  element of the resulting vector is the product (quotient)
of the corresponding elements of the two operand vectors, is allowed.  These
have no overloaded operator associated with them and are obtained by
using 
\bdcode
Vector<double> vecElementProd = vec.dotStar(vec2);
\edcode
where \lcode{dotStar} is a function of \vector\ that produces a new
vector of the same type as \lcode{vec} with elements that are the
product of the corresponding elements of \lcode{vec} and
\lcode{vec2}. The the name \lcode{dotStar} is from the
corresponding \matlab\ operation.  The related function,
\lcode{dotSlash} does the element-wise division.
\end{itemize}

Aside from the overloaded operators and the \lcode{dotStar} and
\lcode{dotSlash} operations, \vector\ has a full list of common
operations that can be performed on vectors.  Here are a few of these
common functions:

\vspace*{1ex}
\begin{tabular}{|l|l|l|} \hline
\lcode{abs} & \lcode{y = x.abs();} & computes the absolute value \\ && of each
element of x \\ \hline
\lcode{setValue} & \lcode{x.setValue(5.6);} & sets each element to 5.6
\\ \hline
\lcode{zero}  & \lcode{x.zero();} & sets each element to zero \\ \hline
\lcode{one}  & \lcode{x.one();}  &  sets each element to one \\ \hline
\end{tabular}
\vspace*{1ex}

\noindent See \vector\ for more information and a complete list of functions.



%================================================================================
\subsection{A First Look at Linear Operators (Matrices)} \label{introLinOp}

Linear operators (or matrices) are much more complicated than vectors,
since they can be large, specially structured, e.g., sparse, and the
operations on them can be quite complex.  Recall that when discussing
vectors, we used the mathematical notion of a vector space and showed
the advantages of this approach.  In dealing with linear operators, we
continue this strategy by defining a linear operator as a mapping from
one vector space to another.  In keeping with the standard
mathematical nomenclature, the linear operator maps a vector from the
``domain'' space to a vector in the ``range'' space.  These vector
spaces are set up exactly as in subsection \ref{introVec}. For
example, we could set up the two spaces as 
\bdcode
VectorSpace<double> domain = new EpetraVectorSpace(...); 
VectorSpace<double> range  = new EpetraVectorSpace(...); 
\edcode
Then a linear operator is defined 
\bdcode
LinearOperator L = new EpetraCRSMatrix(domain, range);
\edcode

We do have to be careful that linear operators are compatible with the
spaces that define them.  In this case, an \lcode{EpetraCRSMatrix} is
designed to work on \lcode{EpetraVector}s.

A common
requirement in  many
applications is solving a linear system of equations.  In this case
the linear operator must be square, i.e., it must map a vector space
to itself.  This means that the domain space is the same as the range
space. We could, therefore, define the square linear operator
\bdcode
LinearOperator A = new EpetraCRSMatrix(domain, domain);
\edcode
where the domain and range spaces are the same.

Next, we must be able to load the matrices as appropriate.  Not every
matrix is loadable; some examples are given below.  But if we do have
a loadable matrix, we can use the method \lcode{setElement(i, j,
  value)} where \lcode{i} is the row index of the element to be set,
\lcode{j} is the column index of the element to be set, and
\lcode{value} is a variable of the scalar type of the linear operator.
The $(i, j)^{\rm th}$ element will be set to \lcode{value}.  It is
also possible to set a collection of values at the same time.  This is
often more efficient when possible.  To do this, we use
the function \lcode{setElements(indices, ..., values)} where ... 

The most common task with a linear operator is to apply it to a
vector, i.e., multiply the vector by the matrix.  In the handle layer
of \thyra, this is simple and natural with the use of the overloaded
operator \lcode{*}. For example, we can write
\bdcode
Vector<double> res = A * x - b;
\edcode
In this computation, the matrix-vector product yields a vector, from which
the vector \lcode{b} is subtracted to give the residual vector \lcode{res}.
A related task is multiplying by the transpose of a matrix.  This is
done as follows:
\bdcode
Vector<double> atx = A.transpose() * x;
\edcode
where the \lcode{transpose} function actually returns a new linear
operator that is the transpose of \lcode{A}.  Note: this does not
create a copy of \lcode{A}; it just creates another handle (pointing
to \lcode{A}) with the property that its \lcode{*} operator applies
the transpose of \lcode{A} to \lcode{x}.  If the transpose must be
applied many times, it is reasonable to save this handle and reuse it:
\bdcode
LinearOperator<double> AT = A.transpose(); 
Vector<double> atx = AT * x;
\edcode


Since solving linear systems is such an important task, we now take a
look at how we do this.  As many people know, there is a wide variety
of methods for solving large linear systems, each of which has its own
features and sets of operators for which it is appropriate.  Often,
the optimal solver may  not be known, so it must be easy to associate a
solver with an operator.  \thyra\ has another handle class to manage
solvers.  Thus, in the code
\bdcode
Solver mySolver = new GMRES(...);
\edcode
\lcode{Solver} is another handle and, in this case, handles the GMRES
solver.  (As before, we ignore the constructor parameters for now.)
Let's assume that \lcode{mySolver} is appropriate for solving systems
with the linear operator \lcode{A} that we just set up.  Providing a
linear operator with a solver is a way of providing the action of the inverse of
the matrix on a vector.  That is, it, like the example conjugate
gradient method above, computes 
\bd
    x = A \inv b
\ed
without ever computing $A \inv$.  (Note that $A\inv$ is almost always
dense, even if $A$ is sparse.  We also know from numerical analysis
that it is highly inefficient to compute $A\inv$ just to solve a
linear system.)  

Now, how do we associate a solver with a linear operator?  We do this
by using the same strategy as we did for transpose.  Thus we can say
\bdcode
x = A.inverse(mySolver) * b;
\edcode
Here, \lcode{A.inverse(mySolver)} returns a linear operator whose
\lcode{*} operator has been overloaded to apply the solver
(\lcode{mySolver}) to \lcode{b}.  As with the transpose operator, we
can save this inverse operator in a new handle and reuse it as
necessary:
\bdcode
LinearOperator<double> Ainv = A.inverse(mySolver); 
x = Ainv * b;
\edcode

Linear operators can be combined in \thyra\ just as they can be
mathematically.  For example, one sometimes creates a symmetric matrix
by averaging a given matrix with its transpose:
\bdcode
LinearOperator<double> ASym = (A + A.transpose()) / 2.0;
\edcode
As before, it is important to understand that at this point, this
matrix is not formed directly.  It is saved in a special linear
operator whose \lcode{*} operator is defined to be the application of
\lcode{A.transpose()} to the target to get a temporary vector, say
\lcode{t}, then the application of \lcode{A} to \lcode{t}, and finally
the division of each element of the result by \lcode{2.0}.
Rather complex ``composite'' operators can be created.  For example,
if the linear operator \lcode{B} is defined, the matrix
\bdcode
LinearOperator<double> H = A.transpose() * B.inverse(mySolver)* A; 
Vector y = H * x;
\edcode
is well defined and computes the equivalent of the mathematical
formula
\bd
     y = (A\trp B\inv A) x.
\ed
Again, we stress that the matrix \lcode{H} is never formed
explicitly.  Code written using these features is easier to read and
debug. 

There are a few other special linear operators that are often useful
in applications.  For example, the identity operator
\bdcode
LinearOperator<double> I = new IdentityOperator<double>(domain);
\edcode
creates an identity operator from \lcode{domain} to itself, since the
identity is, by definition, square.  It can be used in calculations
such as 
\bdcode
Vector<double> y = (A + alpha * I) * x;
\edcode
where \lcode{alpha} is a scalar.  It is very efficient and, of course,
does not store any data. It's \lcode{*} operator simply returns the
target. There is also a ``diagonal'' linear operator, which is a
square matrix that has all zero elements off the diagonal and
arbitrary values on the diagonal as specified by a given vector.
Suppose that the vector \lcode{x} is defined.  Then we can say
\bdcode
LinearOperator<double> D = new DiagonalOperator<double>(x);
\edcode
All that is needed is the vector \lcode{x} from which the domain can
be obtained.

Another special linear operator is the zero linear operator, an
operator that returns zero whenever it is applied.  This matrix is
often used in the construction of another useful linear operator
called a ``block'' linear operator, which we cover next.  A ``block''
operator is a matrix of linear operators.  For example, in
optimization, one often has to consider the so-called ``KKT'' matrix
that has the form:
\bd
      K = \left( \bry{cc} B & A\trp \\ A & 0 \ery \right)
\ed
where $B$ is square $(n \times n)$ matrix, $A$ is an $(m \times n)$
matrix, and the zero block in the bottom right position is $m \times
m)$.  

\thyra\ allows us to set up this block operator in a natural
way. Since all linear operators are constructed with a domain and a
range, we first have to set these up.  To do this, we introduce the
notion of a ``product vector'' and a corresponding ``product vector
space.'' 

Mathematically, a product vector is a vector, each of whose
elements is a vector.  Thus if $x$ and $y$ are vectors (not
necessarily from the same vector space) then we can define the product
vector
\bd
     d = \left( \bry{c} x \\ y \ery \right)
\ed
so that if $x$ is an $n$-dimensional vector and $y$ is an
$m$-dimensional vector, then $d$ is an $(n+ m)$-dimensional vector.  A
simple way to set this up in \thyra\ is, assuming that \lcode{x} and
\lcode{y} are defined \vector s, 
\bdcode
VectorSpace<double> prodVectSpace = 
      new ProductSpace<double>(x.space(), y.space()); 
\edcode
Recall that \lcode{x.space()} is the vector space to which \lcode{x}
belongs. For setting up the matrix \lcode{K}, assuming that the linear
operators \lcode{B} and \lcode{A} are already set up, we first set up
the zero linear operator:
\bdcode
LinearOperator<double> Z = 
     new ZeroOperator<double>(A.domain(), A.domain());
\edcode
Recall that the zero operator is $(m \times m)$ and that $m$ is the
dimension of the range of $A\trp$, which is the domain of $A$.  By
looking at the definition of $K$, we can see that its domain is the
product vector space consisting of the domain of $B$ followed by the
domain of $A\trp$.  Thus we can write
\bdcode
VectorSpace<double> Kspace = 
     new ProductSpace(B.domain(), A.range());
\edcode
Since $K$ is square, its range is the same.  So we now set up $K$
\bdcode
LinearOperator<double> K = new BlockOperator<double>(Kspace, Kspace);
\edcode
and then we can proceed to set the blocks:
\bdcode
K.setBlock(0, 0, B); 
K.setBlock(0, 1, A.transpose(); 
K.setBlock(1, 0, A); 
K.setBlock(1, 1, Z);
\edcode
Because of the fact that the product spaces used to create \lcode{K}
have two elements, \lcode{K} is a block $(2 \times 2)$ matrix.  It is
indexed, as is almost always the case in \cpp, from $(0, 0)$ to $(1,
1)$.  The \lcode{setBlock} function does exactly what you think it
does.  It also checks to be sure that the entries are compatible with
the product vector spaces used to define the operator.  If an
inconsistency is found, an error message is reported.  In subsection
\ref{moreLinOp} we show a different way to set this up that in some
applications is much easier.  Finally, we emphasize again, that no
copies of the underlying matrices are made; the \lcode{BlockOperator}
just keeps a list of the handles to the blocks.  In some applications,
it will be necessary to create the actual matrix; we show how to do
this in subsection \ref{moreLinOp}.



 
 
%  - The range and domain are vector spaces set up exactly as in vector
%  above
%  - Easy to construct, given vec spaces - ex
%  - Many applications involve solving linear systems - so matrix is
%  square or the domain and range spaces are the same.
%  - topics
%      o Loading matrices
%      o Accessing matrix elements
%      o solving systems
%          - a thyra solver
%          - attaching a solver to linear op
%          - solving the system
%          - operations on operators: A + B ; A * BInv * A.transpose() 
%      o We have seen a couple of special linear ops - inverse and
%      transpose
%      o there are others
%          - identity op
%          - diagonal op
%          - scaled op
%          - block op - use KKT as example.

%      o efficiency - not copied, not formed; just uses pointers







%    - must be a way in most languages to set up the space for a vector
%    and load it.
%    - Thyra does not require any knowledge about the underlying
%    implementation or make any assumptions about how the data are
%    stored, but gives a uniform way of creating vectors and indicating operations with
%    vectors. 
%    - As in mathematics,  Vectors in thyra are thought of as members of a Vector Space
%    - The Vector Space holds the properties of the space and can
%    generate members of the space.  There are several concrete
%    VectorSpaces already set up in thyra and more can be added, either
%    by the user for private use or by the thyra team for more general
%    use.  Since epetra is a big thing, that is implemented.
%    - In thyra, part of the design is that the scalar type of the
%    vector is specified by using templates.  This promotes code reuse,
%    reduces the amount of code to write and maintain.  Thus the same
%    code is used to create and work with a vector of integers (int) or
%    a vector of doubles or a vector of complex numbers.
%    - Important! in thyra, you do not create vectors directly, but
%    rather you use the createMember method.  Note that this returns
%    the Vector handle, which, as noted above, handles all of the
%    various vector types in thyra. 

%    - Time for an example:
%    - set up vector space over double-type entries, i.e., vector is an
%    array of doubles
%    - We'll use EPetra as an example, but skip the details of the ctor
%    until later
%       \code{VectorSpace<double> space = new EpetraVectorSpace(...);
%             Vector vec = space.createMember();}

%    - Epetra is meant for vectors split over a number of processors in a
%    parallel processing environment, so the ctor  needs to know
%    the details.  A good way to get the details in is to use
%    ParameterList feature of \teuchos.  We'll show an example of this
%    later.
%    - VectorSpace is a handle that can take care of any vector space,
%    including EpetraVectorSpace.

\subsection{Several Complete Examples}\label{examp}

As mentioned in the introduction, the CG code to illustrate \thyra\
was neither efficient nor complete.  We first give here a complete
code, along with a driver code that runs it, for solving linear
systems using the CG method.


We then show another version that derives from the \thyra\ class
\lcode{SolverBase} that allows us to attach it to a linear operator.
First, here is the simple version followed by some comments.

\VerbatimInput[firstline=1, fontsize=\small,frame=single]{ThyraCG.cpp}

\input{ThyraCG}
 

%\begin{alltt}
%\input{ThyraCG.cpp}
%\end{alltt}

Next we show a complete code that uses \lcode{ThyraCG} to solve a
simple system.  
\VerbatimInput[firstline=1, fontsize=\small,frame=single]{ThyraCGMain.cpp}

Now we show an even more sophisticated version of a CG solver that
derives from \lcode{LinearSolver} and demonstrates  some of other
features of the handle layer of \thyra. We can attach this to a linear
operator and show how it 
works, which we do in the main code that follows. 


\VerbatimInput[firstline=1,
fontsize=\small,frame=single]{ThyraSolverCG.hpp}

\input{ThyraSolverCG}

The following is the main code that uses \lcode{ThyraSolverCG}.  Since
the part of the code that sets up the matrix and right hand side is
the same as above, we just give the lines that are different.  First, we have
to include the new solver class.  This is done with the line
\VerbatimInput[firstline=4, lastline=5,
fontsize=\small,frame=single]{ThyraSolverCGMain.cpp}

The code that uses this is 
\VerbatimInput[firstline=117, 
fontsize=\small,frame=single]{ThyraSolverCGMain.cpp}



%    - a real CG code that uses description/ describe
%It is sometimes useful in debugging a code to know exactly what each
%handle contains.  As mentioned above, the handle layer supports two
%methods to describe the contents of a handle.  If we write 
%\dcode{cout << ``A is '' << A.description();}
%we get the following output....


\subsection{More on Vectors} \label{moreVec}

In this section, we take up a couple of advanced topics related to
\vector s.  

In writing a code that allows an easy change of the underlying vector
type, there may be no obvious way to deduce the type required directly
from the input parameters.  In such cases, one would prefer to simply
tell the class or function what vector type to use in the
calculations.  To do this in \thyra\ we use the concept of
\vectorType. \vectorType\ can be thought of as a ``factory'' design
pattern, i.e., a pattern used to create another object; in this case,
a \vectorSpace, from which, of course, we can then create \vector s. 
As a simple example, here is a code that takes a vector type and
returns a vector whose elements have the value of the index.
\bdcode
template <class scalar> 
Vector<scalar> indexVector(const VectorType<scalar>\& vecType);
VectorSpace<scalar> space = vecType.createSpace();  
Vector<scalar> vec = space.createMember(); 
for  (int i = 0; i < space.dim(); i++) 
  \{ 
    vec[i] = scalar(i); 
  \} 
\edcode

\noindent {\bf Remarks:}
\begin{itemize}
    \item We have assumed that the function \lcode{indexVec} is part
  of a class that has been templated on scalar value.
    \item As required, this allows us to create arbitrary vector
  spaces, create elements of that space, and return them, all without
  ever knowing anything about the underlying implementation.  
\end{itemize}

In subsection \ref{introVec} we mentioned the issue of the need to be
very careful about coding loops over vectors in parallel.  An even more
serious problem is the inner product, or  dot product. Specifically,
if \lcode{vec1} and \lcode{vec2} are already defined and their
elements are set, we can write
\bdcode
double d = vec1 * vec2;
\edcode
which is, in principle, the same as 
\bdcode
double sum = 0.0; 
for (int i = 0; i < vec1.space().dim(); i++) 
  \{ 
     sum += vec1[i] * vec2[i]; 
  \} 
\edcode
But, as we noted above, this may not work correctly in a single
process, multiple data (SPMD) architecture, and, if it does, it will
be very inefficient since each processor will compute all of the
element products and sums, which in turn will require  each processor to
communicate all of its values to all of the other processors. We can
compute local sums on each processor as we did above for adding two
vectors, but then we are left with the problem of forming the final
sum by adding together the partial results contained on each
processor.  (This is the MPI \lcode{allReduce} function.)  In \thyra,
this is all handled automatically and efficiently. 

In the introductory material on vectors, subsection \ref{introVec}, we
mentioned the issue of the meaning of 
\bdcode
Vector<double> vec2 = vec;
\edcode
where \lcode{vec} is already defined.  We pointed out that the meaning
of this is to make the pointer in the handle for \lcode{vec2} the same
as that for \lcode{vec}.  That is, after the execution of that
statement, both \lcode{vec} and \lcode{vec2} point to the same
underlying object.  This was contrasted with the statement
\bdcode
Vector<double> vec2 = vec + vec1;
\edcode
that created a new vector whose elements were the sum of the
corresponding elements in \lcode{vec} and \lcode{vec1} and assigned
this to \lcode{vec2}.  We claimed that this was consistent behavior.
How could this be consistent?  Well, it depends on what you mean by
``consistent.'' It is consistent in the following sense:  Whatever the
result of the right hand side is, its pointer is assigned to
\lcode{vec2}. So, in the case of 
\bdcode
Vector<double> vec2 = vec;
\edcode
the result of the right hand side is, of course, \lcode{vec} so
\lcode{vec}'s pointer gets assigned to \lcode{vec2}.  In the case of 
\bdcode
Vector<double> vec2 = vec + vec1;
\edcode
the result of the right hand side is a temporary vector with the sum
of \lcode{vec} and \lcode{vec1} and the pointer of this temporary is
now assigned to \lcode{vec2}.  Since that temporary vector is managed
by a handle, when it gets assigned to \lcode{vec2}, its reference
counted pointer gets incremented by one and so it doesn't go away
after the operation.

%   consistency of vector a = b and vector a = b + c

%   - VectorType
%    - x = a + b + c + d;
%    - some real vector spaces

\subsection{More on linear operators, solvers, and preconditioners}\label{moreLinOp}
   - forming matrices from composites
   - preconditioners
   - factory for building block ops

\subsection{Troubleshooting}\label{trouble}

The designers and developers of \thyra\ have tried to make this code
as safe as possible and have tried to catch many errors that can
arise.  Nevertheless, there are a few places where a user can we
cannot fully check for potential errors or where certain uses result
in behavior that is not intended.  The design is, admittedly, not
perfect, but represents our best effort at resolving the trade-offs
that inevitably arise when dealing with imperfect languages (\cpp),
imperfect operating systems (Windows and Linux), and, yes, imperfect
designers and developers.  

In this section we will collect some known troublesome areas, so look
through here to see if the suggestions below will help to fix any
problems that arise.  And 
please file a bug report if you find any
problems that you cannot resolve.  


need for copy\\
need for use of rcp(blah, false)

\section{The Abstract Layer of \thyra}\label{abstract}

Ross: I would like to discuss this with you before writing it.


\section{The Design of \thyra}\label{design}

I would like to discuss this with Ross and Kevin before writing it.

\section{Timing for \thyra} \label{timing}

\section{References}\label{refs}

\end{document}

